# -*- coding: utf-8 -*-
"""B365 Bayes

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sGqL0f930vsEQ-Q2Y830NCa_dJnfBHSt
"""

import numpy as np

#Loading data
def load(filename, predict_col, class_num):
  file = np.genfromtxt(filename, delimiter=',', dtype='float')
  #np.random.shuffle(file)
  X = np.delete(file, predict_col, axis=1)
  y = file[:,predict_col]

  return X, y

training_X, training_y = load(r"https://pastebin.com/raw/nfJhV9S5", 5, 2)
validation_X, validation_y = load(r"https://pastebin.com/raw/1gc1x4e3", 5, 2)

#Bayes optimal
correct = 0
tp = 0
tn = 0
fp = 0
fn = 0
data_sizes = []
for i in range(len(validation_y)):
  count=0
  negative=0
  for j in range(len(training_X)):
    if np.array_equal(validation_X[i], training_X[j]):
      count = count+1
      if training_y[j] == 0:
        negative = negative+1
  positive = count-negative
  if positive > negative:
    if validation_y[i] == 1:
      tp = tp + 1
      correct = correct + 1
    else: 
      fp = fp + 1
  if positive <= negative:
    if validation_y[i] == 0:
      tn = tn + 1
      correct = correct + 1
    else: 
      fn = fn + 1
  data_sizes.append(count)

precision = tp/(tp+fp)
recall = tp/(tp+fn)
specificity = tn/(tn+fp)
print("Accuracy: ", correct/len(validation_y), "\nPrecision: ", precision,
      "\nRecall: ", recall, "\nSpecificity: ", specificity)

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline
from matplotlib.pyplot import figure
figure(num=None, figsize=(22, 8), dpi=80, facecolor='w', edgecolor='k')

plt.style.use('ggplot')
x_pos = [i for i, _ in enumerate(data_sizes)]

plt.bar(x_pos, data_sizes, color='green')
plt.xlabel("Data point")
plt.ylabel("Reoccurances")
plt.title("How many times are data points in the validation set represented in training set?")

plt.xticks(x_pos)

plt.show()

#Naive Bayes
prob_neg = sum(np.equal(training_y, 0))/len(training_X)
prob_pos = sum(np.equal(training_y, 1))/len(training_X)
prob_table = np.array([[0.0, 0.0, 0.0, 0.0, 0.0],
                      [0.0, 0.0, 0.0, 0.0, 0.0]])

for i in range(len(training_X)):
  if training_y[i] == 0:
    prob_table[0] = prob_table[0] + training_X[i]
  else:
    prob_table[1] = prob_table[1] + training_X[i]

prob_table[0] = prob_table[0]/sum(np.equal(training_y, 0))
prob_table[1] = prob_table[1]/sum(np.equal(training_y, 1))
print("Probability table: ", "\n", prob_table)
print()

tp = 0
tn = 0
fp = 0
fn = 0
correct = 0
for i in range(len(validation_X)):
  test_neg = prob_neg
  test_pos = prob_pos
  classification = 0
  for j in range(5):
    if validation_X[i, j] == 0:
      test_neg = test_neg*(1-prob_table[0, j])
      test_pos = test_pos*(1-prob_table[1, j])
    else:
      test_neg = test_neg*(prob_table[0, j])
      test_pos = test_pos*(prob_table[1, j])
  if test_pos > test_neg:
    classification = 1
  if classification == validation_y[i]:
    correct = correct + 1
    if classification == 1:
      tp = tp+1
    else:
      tn = tn+1
  else:
    if classification == 1:
      fp = fp+1
    else:
      fn = fn+1
      
precision = tp/(tp+fp)
recall = tp/(tp+fn)
specificity = tn/(tn+fp)
print("Accuracy: ", correct/len(validation_y), "\nPrecision: ", precision,
      "\nRecall: ", recall, "\nSpecificity: ", specificity)